# cricinfo_webscrapper

Description- The Cricinfo Web Scraper is a tool built to extract detailed information about cricketers (such as scores, centuries, batting stats, and more) from a webpage using web scraping techniques. The project was developed using HTML, CSS, and JavaScript, and its main goal is to collect live statistics of cricket players from a publicly available website like ESPN Cricinfo. This data can then be processed and displayed for analysis, visualization, or other use cases.

Tech Stack
HTML:
HTML is used for structuring the webpage and creating the user interface (UI) elements. In this case, HTML is used to build forms or buttons to allow users to trigger the web scraping process, as well as to display the extracted data in a readable format.

CSS:
CSS is used for styling the webpage. It ensures the UI is visually appealing and user-friendly. With CSS, you can control layout, fonts, and colors, making the results of the scraper easy to read and understand.

JavaScript:
JavaScript is the core technology for implementing the web scraping logic. It is used to dynamically fetch data from the web page, parse the HTML content, and extract the necessary information about batsmen's performances. In this case, JavaScript's ability to interact with the DOM (Document Object Model) and handle asynchronous tasks (like fetching data) is crucial.

Web Scraping Libraries/APIs (If any):
If you used any libraries or external APIs, you can mention tools like:

Axios / Fetch API: Used to make HTTP requests and fetch HTML content from the Cricinfo website.
Cheerio: A JavaScript library that helps parse and traverse HTML. If you're using Node.js on the backend, this would be useful for scraping, although you might use plain JavaScript on the front end as well.
RegEx (Regular Expressions): If needed, RegEx patterns might be used to filter or extract specific pieces of information from the raw HTML.
